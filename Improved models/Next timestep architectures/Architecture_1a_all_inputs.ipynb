{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Architecture 1a - Single column next timestep prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADITYA\\AppData\\Local\\Temp\\ipykernel_42704\\6720161.py:2: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\ADITYA\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel('C:/Users/ADITYA/OneDrive - Imperial College London/Year 4/FYP/Final-year-project/VScode/Data/Dataset_scaled_denoised.xlsx')\n",
    "data = data[data['I'] == 1.6]\n",
    "X = data.iloc[1:-1,:11]\n",
    "X = X.drop('I', axis = 1)\n",
    "y = data.iloc[2:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_numpy = X.values\n",
    "y_numpy = y.values\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_numpy, y_numpy, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\ADITYA\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\ADITYA\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:From c:\\Users\\ADITYA\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "3601/3601 [==============================] - 4s 791us/step - loss: 0.0162\n",
      "Epoch 2/20\n",
      "3601/3601 [==============================] - 3s 807us/step - loss: 8.0757e-05\n",
      "Epoch 3/20\n",
      "3601/3601 [==============================] - 3s 778us/step - loss: 7.2089e-05\n",
      "Epoch 4/20\n",
      "3601/3601 [==============================] - 3s 790us/step - loss: 7.0410e-05\n",
      "Epoch 5/20\n",
      "3601/3601 [==============================] - 3s 849us/step - loss: 6.7507e-05\n",
      "Epoch 6/20\n",
      "3601/3601 [==============================] - 3s 792us/step - loss: 6.5777e-05\n",
      "Epoch 7/20\n",
      "3601/3601 [==============================] - 3s 770us/step - loss: 6.4369e-05\n",
      "Epoch 8/20\n",
      "3601/3601 [==============================] - 3s 760us/step - loss: 6.3508e-05\n",
      "Epoch 9/20\n",
      "3601/3601 [==============================] - 3s 757us/step - loss: 6.3256e-05\n",
      "Epoch 10/20\n",
      "3601/3601 [==============================] - 3s 747us/step - loss: 6.4950e-05\n",
      "Epoch 11/20\n",
      "3601/3601 [==============================] - 3s 772us/step - loss: 6.4710e-05\n",
      "Epoch 12/20\n",
      "3601/3601 [==============================] - 3s 753us/step - loss: 6.1344e-05\n",
      "Epoch 13/20\n",
      "3601/3601 [==============================] - 3s 792us/step - loss: 6.4807e-05\n",
      "Epoch 14/20\n",
      "3601/3601 [==============================] - 3s 817us/step - loss: 6.3338e-05\n",
      "Epoch 15/20\n",
      "3601/3601 [==============================] - 3s 851us/step - loss: 6.2014e-05\n",
      "Epoch 16/20\n",
      "3601/3601 [==============================] - 3s 796us/step - loss: 6.5042e-05\n",
      "Epoch 17/20\n",
      "3601/3601 [==============================] - 3s 859us/step - loss: 6.1969e-05\n",
      "Epoch 18/20\n",
      "3601/3601 [==============================] - 3s 899us/step - loss: 6.2751e-05\n",
      "Epoch 19/20\n",
      "3601/3601 [==============================] - 3s 837us/step - loss: 6.1793e-05\n",
      "Epoch 20/20\n",
      "3601/3601 [==============================] - 4s 1ms/step - loss: 6.2993e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x25571a57810>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(10, activation='relu', input_dim = 10))\n",
    "model.add(Dense(5,activation = 'relu'))\n",
    "# model.add(Dense(4,activation = 'relu'))\n",
    "model.add(Dense(1, activation='linear'))  # Output layer with a multiple neurons\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "model.fit(X_train, y_train, epochs=20, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "901/901 [==============================] - 1s 638us/step - loss: 1.9968e-06\n",
      "Mean Squared Error on Test Set: 1.996771061385516e-06\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test set\n",
    "mse = model.evaluate(X_test, y_test)\n",
    "print(f\"Mean Squared Error on Test Set: {mse}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
