{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forecasting individual concentraions without partial currents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Importing libraries and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADITYA\\AppData\\Local\\Temp\\ipykernel_32756\\1782324082.py:2: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\ADITYA\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.utils import *\n",
    "\n",
    "\n",
    "# from Data_sorting import Data_formatter_cycles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel('C:/Users/ADITYA/OneDrive - Imperial College London/Year 4/FYP/Final-year-project/VScode//Data/Dataset_scaled_denoised.xlsx')\n",
    "data = data[data['I'] == 1.6]\n",
    "X = data.iloc[1:,:9]\n",
    "X = X.drop('I', axis = 1)\n",
    "y = data.iloc[1:,11:16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          S8_cur    S4_cur    S2_cur    S1_cur     V_cur    Sp_cur        EH  \\\n",
      "1       2.914558 -2.960002 -0.929154 -0.232859  3.965686 -0.925127  3.914506   \n",
      "2       2.914450 -2.959872 -0.929154 -0.232859  3.953539 -0.925127  3.902619   \n",
      "3       2.914342 -2.959743 -0.929154 -0.232858  3.941755 -0.925127  3.891043   \n",
      "4       2.914234 -2.959613 -0.929154 -0.232858  3.930271 -0.925127  3.879762   \n",
      "5       2.914126 -2.959483 -0.929154 -0.232858  3.919073 -0.925127  3.868761   \n",
      "...          ...       ...       ...       ...       ...       ...       ...   \n",
      "144008 -0.715584 -0.685340  2.665422 -0.146794 -0.871377  2.664142 -0.874464   \n",
      "144009 -0.715584 -0.685383  2.665497 -0.146795 -0.871381  2.664216 -0.874468   \n",
      "144010 -0.715584 -0.685426  2.665571 -0.146795 -0.871385  2.664290 -0.874473   \n",
      "144011 -0.715584 -0.685469  2.665645 -0.146796 -0.871390  2.664365 -0.874477   \n",
      "144012 -0.715584 -0.685512  2.665719 -0.146797 -0.871394  2.664439 -0.874481   \n",
      "\n",
      "              EL  \n",
      "1       4.072668  \n",
      "2       4.059976  \n",
      "3       4.047754  \n",
      "4       4.035847  \n",
      "5       4.024235  \n",
      "...          ...  \n",
      "144008 -0.864718  \n",
      "144009 -0.864723  \n",
      "144010 -0.864727  \n",
      "144011 -0.864732  \n",
      "144012 -0.864736  \n",
      "\n",
      "[144012 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# S8 Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_S8 = X.copy()\n",
    "X_S8 = X_S8.drop('S1_cur', axis = 1)\n",
    "X_S8 = X_S8.drop('S2_cur', axis = 1)\n",
    "X_S8 = X_S8.drop('Sp_cur', axis = 1)\n",
    "# X_S8 = X_S8.drop('V_cur', axis = 1)\n",
    "# X_S8 = X_S8.drop('iH', axis = 1)\n",
    "   \n",
    "\n",
    "y_S8 = y['S8_cur.1']\n",
    "\n",
    "X_numpy_S8 = X_S8.values\n",
    "y_numpy_S8 = y_S8.values\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train_S8, X_test_S8, y_train_S8, y_test_S8 = train_test_split(X_numpy_S8, y_numpy_S8, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3601/3601 [==============================] - 3s 732us/step - loss: 0.0124\n",
      "Epoch 2/20\n",
      "3601/3601 [==============================] - 3s 758us/step - loss: 6.2025e-06\n",
      "Epoch 3/20\n",
      "3601/3601 [==============================] - 3s 754us/step - loss: 3.0498e-06\n",
      "Epoch 4/20\n",
      "3601/3601 [==============================] - 3s 741us/step - loss: 3.2809e-06\n",
      "Epoch 5/20\n",
      "3601/3601 [==============================] - 3s 761us/step - loss: 3.2186e-06\n",
      "Epoch 6/20\n",
      "3601/3601 [==============================] - 3s 756us/step - loss: 2.4703e-06\n",
      "Epoch 7/20\n",
      "3601/3601 [==============================] - 3s 748us/step - loss: 2.0068e-06\n",
      "Epoch 8/20\n",
      "3601/3601 [==============================] - 3s 752us/step - loss: 2.1774e-06\n",
      "Epoch 9/20\n",
      "3601/3601 [==============================] - 3s 743us/step - loss: 2.2225e-06\n",
      "Epoch 10/20\n",
      "3601/3601 [==============================] - 3s 718us/step - loss: 2.1963e-06\n",
      "Epoch 11/20\n",
      "3601/3601 [==============================] - 3s 742us/step - loss: 1.7371e-06\n",
      "Epoch 12/20\n",
      "3601/3601 [==============================] - 3s 784us/step - loss: 1.9562e-06\n",
      "Epoch 13/20\n",
      "3601/3601 [==============================] - 3s 742us/step - loss: 5.8557e-06\n",
      "Epoch 14/20\n",
      "3601/3601 [==============================] - 3s 776us/step - loss: 1.5502e-06\n",
      "Epoch 15/20\n",
      "3601/3601 [==============================] - 3s 784us/step - loss: 3.1640e-06\n",
      "Epoch 16/20\n",
      "3601/3601 [==============================] - 3s 751us/step - loss: 1.6560e-06\n",
      "Epoch 17/20\n",
      "3601/3601 [==============================] - 3s 756us/step - loss: 3.0957e-06\n",
      "Epoch 18/20\n",
      "3601/3601 [==============================] - 3s 751us/step - loss: 1.6756e-06\n",
      "Epoch 19/20\n",
      "3601/3601 [==============================] - 3s 730us/step - loss: 2.6402e-06\n",
      "Epoch 20/20\n",
      "3601/3601 [==============================] - 3s 797us/step - loss: 1.9783e-06\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1a359f26c50>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model8 = Sequential()\n",
    "model8.add(Dense(10, activation='relu', input_dim = 5))\n",
    "# model.add(Dense(6, activation='relu'))\n",
    "# model.add(Dense(12,activation = 'relu'))\n",
    "model8.add(Dense(5,activation = 'relu'))\n",
    "# model.add(Dense(10, activation='relu'))\n",
    "model8.add(Dense(1, activation='linear'))  # Output layer with a multiple neurons\n",
    "\n",
    "# Compile the model\n",
    "model8.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "model8.fit(X_train_S8, y_train_S8, epochs=20, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "901/901 [==============================] - 1s 647us/step - loss: 4.1473e-07\n",
      "Mean Squared Error on Test Set: 4.1472571865597274e-07\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test set\n",
    "mse = model8.evaluate(X_test_S8, y_test_S8)\n",
    "print(f\"Mean Squared Error on Test Set: {mse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# S4 prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_S4 = X.copy()\n",
    "# X_S4 = X_S4.drop('iL', axis = 1)\n",
    "# X_S4 = X_S4.drop('iH', axis = 1)\n",
    "X_S4 = X_S4.drop('S8_cur', axis = 1)\n",
    "\n",
    "y_S4 = y['S4_cur.1']\n",
    "\n",
    "X_numpy_S4 = X_S4.values\n",
    "y_numpy_S4 = y_S4.values\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train_S4, X_test_S4, y_train_S4, y_test_S4 = train_test_split(X_numpy_S4, y_numpy_S4, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "3601/3601 [==============================] - 3s 794us/step - loss: 0.0595\n",
      "Epoch 2/20\n",
      "3601/3601 [==============================] - 3s 828us/step - loss: 2.3103e-04\n",
      "Epoch 3/20\n",
      "3601/3601 [==============================] - 3s 810us/step - loss: 3.1810e-05\n",
      "Epoch 4/20\n",
      "3601/3601 [==============================] - 3s 809us/step - loss: 2.0433e-05\n",
      "Epoch 5/20\n",
      "3601/3601 [==============================] - 3s 801us/step - loss: 1.2829e-05\n",
      "Epoch 6/20\n",
      "3601/3601 [==============================] - 3s 777us/step - loss: 6.9484e-06\n",
      "Epoch 7/20\n",
      "3601/3601 [==============================] - 3s 774us/step - loss: 4.2662e-06\n",
      "Epoch 8/20\n",
      "3601/3601 [==============================] - 3s 736us/step - loss: 3.8594e-06\n",
      "Epoch 9/20\n",
      "3601/3601 [==============================] - 3s 776us/step - loss: 4.1172e-06\n",
      "Epoch 10/20\n",
      "3601/3601 [==============================] - 3s 781us/step - loss: 3.6695e-06\n",
      "Epoch 11/20\n",
      "3601/3601 [==============================] - 3s 778us/step - loss: 3.8432e-06\n",
      "Epoch 12/20\n",
      "3601/3601 [==============================] - 3s 826us/step - loss: 3.1632e-06\n",
      "Epoch 13/20\n",
      "3601/3601 [==============================] - 3s 811us/step - loss: 3.7473e-06\n",
      "Epoch 14/20\n",
      "3601/3601 [==============================] - 3s 807us/step - loss: 3.0166e-06\n",
      "Epoch 15/20\n",
      "3601/3601 [==============================] - 3s 810us/step - loss: 2.9710e-06\n",
      "Epoch 16/20\n",
      "3601/3601 [==============================] - 3s 798us/step - loss: 2.6137e-06\n",
      "Epoch 17/20\n",
      "3601/3601 [==============================] - 3s 781us/step - loss: 2.9493e-06\n",
      "Epoch 18/20\n",
      "3601/3601 [==============================] - 3s 768us/step - loss: 2.5702e-06\n",
      "Epoch 19/20\n",
      "3601/3601 [==============================] - 3s 769us/step - loss: 2.9182e-06\n",
      "Epoch 20/20\n",
      "3601/3601 [==============================] - 3s 785us/step - loss: 2.8327e-06\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1a36f1c7510>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4 = Sequential()\n",
    "model4.add(Dense(7, activation='relu', input_dim = 7))\n",
    "# model.add(Dense(6, activation='relu'))\n",
    "# model.add(Dense(12,activation = 'relu'))\n",
    "model4.add(Dense(4,activation = 'relu'))\n",
    "model4.add(Dense(2,activation = 'relu'))\n",
    "# model.add(Dense(10, activation='relu'))\n",
    "model4.add(Dense(1, activation='linear'))  # Output layer with a multiple neurons\n",
    "\n",
    "# Compile the model\n",
    "model4.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "model4.fit(X_train_S4, y_train_S4, epochs=20, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "901/901 [==============================] - 1s 629us/step - loss: 8.4563e-07\n",
      "Mean Squared Error on Test Set: 8.456327122985385e-07\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test set\n",
    "mse = model4.evaluate(X_test_S4, y_test_S4)\n",
    "print(f\"Mean Squared Error on Test Set: {mse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# S2 prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_S2 = X.copy()\n",
    "X_S2 = X_S2.drop('EH', axis = 1)\n",
    "X_S2 = X_S2.drop('S8_cur', axis = 1)\n",
    "X_S2 = X_S2.drop('V_cur', axis = 1)\n",
    "\n",
    "y_S2 = y['S2_cur.1']\n",
    "\n",
    "X_numpy_S2 = X_S2.values\n",
    "y_numpy_S2 = y_S2.values\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train_S2, X_test_S2, y_train_S2, y_test_S2 = train_test_split(X_numpy_S2, y_numpy_S2, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "3601/3601 [==============================] - 3s 780us/step - loss: 0.0449\n",
      "Epoch 2/20\n",
      "3601/3601 [==============================] - 3s 754us/step - loss: 9.1706e-05\n",
      "Epoch 3/20\n",
      "3601/3601 [==============================] - 3s 733us/step - loss: 2.0122e-05\n",
      "Epoch 4/20\n",
      "3601/3601 [==============================] - 3s 747us/step - loss: 1.0795e-05\n",
      "Epoch 5/20\n",
      "3601/3601 [==============================] - 3s 738us/step - loss: 7.0133e-06\n",
      "Epoch 6/20\n",
      "3601/3601 [==============================] - 3s 733us/step - loss: 4.3017e-06\n",
      "Epoch 7/20\n",
      "3601/3601 [==============================] - 3s 743us/step - loss: 2.1470e-06\n",
      "Epoch 8/20\n",
      "3601/3601 [==============================] - 3s 755us/step - loss: 1.5877e-06\n",
      "Epoch 9/20\n",
      "3601/3601 [==============================] - 3s 750us/step - loss: 1.3155e-06\n",
      "Epoch 10/20\n",
      "3601/3601 [==============================] - 3s 744us/step - loss: 1.3341e-06\n",
      "Epoch 11/20\n",
      "3601/3601 [==============================] - 3s 742us/step - loss: 8.1072e-07\n",
      "Epoch 12/20\n",
      "3601/3601 [==============================] - 3s 751us/step - loss: 8.4905e-07\n",
      "Epoch 13/20\n",
      "3601/3601 [==============================] - 3s 761us/step - loss: 7.1908e-07\n",
      "Epoch 14/20\n",
      "3601/3601 [==============================] - 3s 763us/step - loss: 7.6012e-07\n",
      "Epoch 15/20\n",
      "3601/3601 [==============================] - 3s 757us/step - loss: 1.2537e-06\n",
      "Epoch 16/20\n",
      "3601/3601 [==============================] - 3s 747us/step - loss: 7.5409e-07\n",
      "Epoch 17/20\n",
      "3601/3601 [==============================] - 3s 746us/step - loss: 5.1006e-07\n",
      "Epoch 18/20\n",
      "3601/3601 [==============================] - 3s 763us/step - loss: 1.4993e-06\n",
      "Epoch 19/20\n",
      "3601/3601 [==============================] - 3s 743us/step - loss: 3.9111e-07\n",
      "Epoch 20/20\n",
      "3601/3601 [==============================] - 3s 766us/step - loss: 1.0188e-06\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1a3437f1e10>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = Sequential()\n",
    "model2.add(Dense(5, activation='relu', input_dim = 5))\n",
    "# model.add(Dense(6, activation='relu'))\n",
    "# model.add(Dense(12,activation = 'relu'))\n",
    "model2.add(Dense(2,activation = 'relu'))\n",
    "# model.add(Dense(10, activation='relu'))\n",
    "model2.add(Dense(1, activation='linear'))  # Output layer with a multiple neurons\n",
    "\n",
    "# Compile the model\n",
    "model2.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "model2.fit(X_train_S2, y_train_S2, epochs=20, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "901/901 [==============================] - 1s 627us/step - loss: 5.2132e-08\n",
      "Mean Squared Error on Test Set: 5.2131738925709215e-08\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test set\n",
    "mse = model2.evaluate(X_test_S2, y_test_S2)\n",
    "print(f\"Mean Squared Error on Test Set: {mse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# S1 prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_S1 = X.copy()\n",
    "X_S1 = X_S1.drop('S8_cur', axis = 1)\n",
    "# X_S1 = X_S1.drop('Sp_cur', axis = 1)\n",
    "# X_S1 = X_S1.drop('S2_cur', axis = 1)\n",
    "\n",
    "\n",
    "y_S1 = y['S1_cur.1']\n",
    "\n",
    "X_numpy_S1 = X_S1.values\n",
    "y_numpy_S1 = y_S1.values\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train_S1, X_test_S1, y_train_S1, y_test_S1 = train_test_split(X_numpy_S1, y_numpy_S1, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "3601/3601 [==============================] - 4s 915us/step - loss: 0.0975\n",
      "Epoch 2/100\n",
      "3601/3601 [==============================] - 3s 923us/step - loss: 6.0778e-04\n",
      "Epoch 3/100\n",
      "3601/3601 [==============================] - 3s 936us/step - loss: 4.9315e-04\n",
      "Epoch 4/100\n",
      "3601/3601 [==============================] - 3s 897us/step - loss: 5.1759e-04\n",
      "Epoch 5/100\n",
      "3601/3601 [==============================] - 3s 852us/step - loss: 4.2429e-04\n",
      "Epoch 6/100\n",
      "3601/3601 [==============================] - 3s 860us/step - loss: 3.1375e-04\n",
      "Epoch 7/100\n",
      "3601/3601 [==============================] - 3s 819us/step - loss: 3.7208e-04\n",
      "Epoch 8/100\n",
      "3601/3601 [==============================] - 3s 843us/step - loss: 2.9909e-04\n",
      "Epoch 9/100\n",
      "3601/3601 [==============================] - 4s 1ms/step - loss: 3.6745e-04\n",
      "Epoch 10/100\n",
      "3601/3601 [==============================] - 3s 892us/step - loss: 2.7967e-04\n",
      "Epoch 11/100\n",
      "3601/3601 [==============================] - 3s 900us/step - loss: 1.6440e-04\n",
      "Epoch 12/100\n",
      "3601/3601 [==============================] - 3s 898us/step - loss: 2.5205e-04\n",
      "Epoch 13/100\n",
      "3601/3601 [==============================] - 3s 884us/step - loss: 2.2265e-04\n",
      "Epoch 14/100\n",
      "3601/3601 [==============================] - 3s 790us/step - loss: 1.9527e-04\n",
      "Epoch 15/100\n",
      "3601/3601 [==============================] - 3s 847us/step - loss: 2.1513e-04\n",
      "Epoch 16/100\n",
      "3601/3601 [==============================] - 3s 842us/step - loss: 1.7152e-04\n",
      "Epoch 17/100\n",
      "3601/3601 [==============================] - 3s 843us/step - loss: 2.1712e-04\n",
      "Epoch 18/100\n",
      "3601/3601 [==============================] - 3s 820us/step - loss: 1.8689e-04\n",
      "Epoch 19/100\n",
      "3601/3601 [==============================] - 3s 833us/step - loss: 1.6912e-04\n",
      "Epoch 20/100\n",
      "3601/3601 [==============================] - 3s 871us/step - loss: 1.8190e-04\n",
      "Epoch 21/100\n",
      "3601/3601 [==============================] - 3s 828us/step - loss: 1.7697e-04\n",
      "Epoch 22/100\n",
      "3601/3601 [==============================] - 3s 890us/step - loss: 1.7772e-04\n",
      "Epoch 23/100\n",
      "3601/3601 [==============================] - 3s 816us/step - loss: 2.0986e-04\n",
      "Epoch 24/100\n",
      "3601/3601 [==============================] - 3s 859us/step - loss: 1.6715e-04\n",
      "Epoch 25/100\n",
      "3601/3601 [==============================] - 3s 846us/step - loss: 1.6255e-04\n",
      "Epoch 26/100\n",
      "3601/3601 [==============================] - 3s 905us/step - loss: 1.4868e-04\n",
      "Epoch 27/100\n",
      "3601/3601 [==============================] - 3s 871us/step - loss: 1.8295e-04\n",
      "Epoch 28/100\n",
      "3601/3601 [==============================] - 3s 844us/step - loss: 9.0129e-05\n",
      "Epoch 29/100\n",
      "3601/3601 [==============================] - 3s 841us/step - loss: 9.8128e-05\n",
      "Epoch 30/100\n",
      "3601/3601 [==============================] - 3s 889us/step - loss: 1.1316e-04\n",
      "Epoch 31/100\n",
      "3601/3601 [==============================] - 3s 841us/step - loss: 1.2470e-04\n",
      "Epoch 32/100\n",
      "3601/3601 [==============================] - 3s 867us/step - loss: 1.0180e-04\n",
      "Epoch 33/100\n",
      "3601/3601 [==============================] - 3s 836us/step - loss: 9.7853e-05\n",
      "Epoch 34/100\n",
      "3601/3601 [==============================] - 3s 883us/step - loss: 1.4807e-04\n",
      "Epoch 35/100\n",
      "3601/3601 [==============================] - 3s 829us/step - loss: 1.0030e-04\n",
      "Epoch 36/100\n",
      "3601/3601 [==============================] - 3s 881us/step - loss: 1.1011e-04\n",
      "Epoch 37/100\n",
      "3601/3601 [==============================] - 3s 851us/step - loss: 1.2289e-04\n",
      "Epoch 38/100\n",
      "3601/3601 [==============================] - 3s 817us/step - loss: 9.5955e-05\n",
      "Epoch 39/100\n",
      "3601/3601 [==============================] - 3s 875us/step - loss: 1.0432e-04\n",
      "Epoch 40/100\n",
      "3601/3601 [==============================] - 3s 952us/step - loss: 1.0908e-04\n",
      "Epoch 41/100\n",
      "3601/3601 [==============================] - 3s 912us/step - loss: 8.8867e-05\n",
      "Epoch 42/100\n",
      "3601/3601 [==============================] - 3s 903us/step - loss: 9.1647e-05\n",
      "Epoch 43/100\n",
      "3601/3601 [==============================] - 3s 921us/step - loss: 1.2052e-04\n",
      "Epoch 44/100\n",
      "3601/3601 [==============================] - 3s 902us/step - loss: 1.0563e-04\n",
      "Epoch 45/100\n",
      "3601/3601 [==============================] - 3s 883us/step - loss: 8.8585e-05\n",
      "Epoch 46/100\n",
      "3601/3601 [==============================] - 3s 860us/step - loss: 1.0168e-04\n",
      "Epoch 47/100\n",
      "3601/3601 [==============================] - 3s 892us/step - loss: 7.5996e-05\n",
      "Epoch 48/100\n",
      "3601/3601 [==============================] - 3s 892us/step - loss: 1.0690e-04\n",
      "Epoch 49/100\n",
      "3601/3601 [==============================] - 3s 822us/step - loss: 8.2270e-05\n",
      "Epoch 50/100\n",
      "3601/3601 [==============================] - 3s 788us/step - loss: 7.9661e-05\n",
      "Epoch 51/100\n",
      "3601/3601 [==============================] - 3s 796us/step - loss: 7.7307e-05\n",
      "Epoch 52/100\n",
      "3601/3601 [==============================] - 3s 795us/step - loss: 1.0666e-04\n",
      "Epoch 53/100\n",
      "3601/3601 [==============================] - 3s 810us/step - loss: 8.7986e-05\n",
      "Epoch 54/100\n",
      "3601/3601 [==============================] - 3s 810us/step - loss: 8.9543e-05\n",
      "Epoch 55/100\n",
      "3601/3601 [==============================] - 3s 862us/step - loss: 5.4984e-05\n",
      "Epoch 56/100\n",
      "3601/3601 [==============================] - 3s 869us/step - loss: 7.4309e-05\n",
      "Epoch 57/100\n",
      "3601/3601 [==============================] - 3s 833us/step - loss: 9.2933e-05\n",
      "Epoch 58/100\n",
      "3601/3601 [==============================] - 3s 834us/step - loss: 8.3702e-05\n",
      "Epoch 59/100\n",
      "3601/3601 [==============================] - 3s 843us/step - loss: 9.2361e-05\n",
      "Epoch 60/100\n",
      "3601/3601 [==============================] - 3s 847us/step - loss: 7.7448e-05\n",
      "Epoch 61/100\n",
      "3601/3601 [==============================] - 3s 839us/step - loss: 1.0245e-04\n",
      "Epoch 62/100\n",
      "3601/3601 [==============================] - 3s 844us/step - loss: 8.1115e-05\n",
      "Epoch 63/100\n",
      "3601/3601 [==============================] - 3s 856us/step - loss: 7.5508e-05\n",
      "Epoch 64/100\n",
      "3601/3601 [==============================] - 3s 845us/step - loss: 7.3438e-05\n",
      "Epoch 65/100\n",
      "3601/3601 [==============================] - 3s 851us/step - loss: 7.5725e-05\n",
      "Epoch 66/100\n",
      "3601/3601 [==============================] - 3s 842us/step - loss: 7.5616e-05\n",
      "Epoch 67/100\n",
      "3601/3601 [==============================] - 3s 838us/step - loss: 6.8925e-05\n",
      "Epoch 68/100\n",
      "3601/3601 [==============================] - 3s 846us/step - loss: 6.0156e-05\n",
      "Epoch 69/100\n",
      "3601/3601 [==============================] - 3s 863us/step - loss: 6.4585e-05\n",
      "Epoch 70/100\n",
      "3601/3601 [==============================] - 3s 824us/step - loss: 6.8809e-05\n",
      "Epoch 71/100\n",
      "3601/3601 [==============================] - 3s 877us/step - loss: 6.3779e-05\n",
      "Epoch 72/100\n",
      "3601/3601 [==============================] - 3s 841us/step - loss: 6.0366e-05\n",
      "Epoch 73/100\n",
      "3601/3601 [==============================] - 3s 836us/step - loss: 5.8171e-05\n",
      "Epoch 74/100\n",
      "3601/3601 [==============================] - 3s 863us/step - loss: 6.5504e-05\n",
      "Epoch 75/100\n",
      "3601/3601 [==============================] - 3s 896us/step - loss: 7.0328e-05\n",
      "Epoch 76/100\n",
      "3601/3601 [==============================] - 3s 861us/step - loss: 1.4493e-04\n",
      "Epoch 77/100\n",
      "3601/3601 [==============================] - 3s 856us/step - loss: 8.1386e-05\n",
      "Epoch 78/100\n",
      "3601/3601 [==============================] - 3s 850us/step - loss: 5.6059e-05\n",
      "Epoch 79/100\n",
      "3601/3601 [==============================] - 3s 842us/step - loss: 6.1695e-05\n",
      "Epoch 80/100\n",
      "3601/3601 [==============================] - 3s 835us/step - loss: 6.5345e-05\n",
      "Epoch 81/100\n",
      "3601/3601 [==============================] - 3s 851us/step - loss: 6.1701e-05\n",
      "Epoch 82/100\n",
      "3601/3601 [==============================] - 3s 850us/step - loss: 7.9118e-05\n",
      "Epoch 83/100\n",
      "3601/3601 [==============================] - 3s 866us/step - loss: 4.7701e-05\n",
      "Epoch 84/100\n",
      "3601/3601 [==============================] - 3s 863us/step - loss: 4.0173e-05\n",
      "Epoch 85/100\n",
      "3601/3601 [==============================] - 3s 883us/step - loss: 7.3528e-05\n",
      "Epoch 86/100\n",
      "3601/3601 [==============================] - 3s 861us/step - loss: 5.5772e-05\n",
      "Epoch 87/100\n",
      "3601/3601 [==============================] - 3s 861us/step - loss: 7.3576e-05\n",
      "Epoch 88/100\n",
      "3601/3601 [==============================] - 3s 816us/step - loss: 5.6335e-05\n",
      "Epoch 89/100\n",
      "3601/3601 [==============================] - 3s 793us/step - loss: 5.2104e-05\n",
      "Epoch 90/100\n",
      "3601/3601 [==============================] - 3s 857us/step - loss: 6.2935e-05\n",
      "Epoch 91/100\n",
      "3601/3601 [==============================] - 3s 893us/step - loss: 5.2623e-05\n",
      "Epoch 92/100\n",
      "3601/3601 [==============================] - 3s 907us/step - loss: 5.1022e-05\n",
      "Epoch 93/100\n",
      "3601/3601 [==============================] - 3s 796us/step - loss: 5.3442e-05\n",
      "Epoch 94/100\n",
      "3601/3601 [==============================] - 3s 772us/step - loss: 6.8961e-05\n",
      "Epoch 95/100\n",
      "3601/3601 [==============================] - 3s 941us/step - loss: 6.6396e-05\n",
      "Epoch 96/100\n",
      "3601/3601 [==============================] - 3s 906us/step - loss: 5.1780e-05\n",
      "Epoch 97/100\n",
      "3601/3601 [==============================] - 3s 894us/step - loss: 9.0745e-05\n",
      "Epoch 98/100\n",
      "3601/3601 [==============================] - 3s 863us/step - loss: 4.9100e-05\n",
      "Epoch 99/100\n",
      "3601/3601 [==============================] - 3s 787us/step - loss: 5.7744e-05\n",
      "Epoch 100/100\n",
      "3601/3601 [==============================] - 3s 835us/step - loss: 4.8163e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1a38d045010>"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1 = Sequential()\n",
    "model1.add(Dense(64, activation='relu', input_dim = 7))\n",
    "# model.add(Dense(6, activation='relu'))\n",
    "# model1.add(Dense(12,activation = 'relu'))\n",
    "model1.add(Dense(32,activation = 'relu'))\n",
    "model1.add(Dense(16,activation = 'sigmoid'))\n",
    "# model1.add(Dense(1,activation = 'tanh'))\n",
    "model1.add(Dense(4,activation = 'relu'))\n",
    "# model.add(Dense(10, activation='relu'))\n",
    "model1.add(Dense(1, activation='linear'))  # Output layer with a multiple neurons\n",
    "\n",
    "# Compile the model\n",
    "model1.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "model1.fit(X_train_S1, y_train_S1, epochs=100, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "901/901 [==============================] - 1s 698us/step - loss: 5.8081e-05\n",
      "Mean Squared Error on Test Set: 5.808112837257795e-05\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test set\n",
    "mse = model1.evaluate(X_test_S1, y_test_S1)\n",
    "print(f\"Mean Squared Error on Test Set: {mse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sp prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_Sp = X.copy()\n",
    "X_Sp = X_Sp.drop('EH', axis = 1)\n",
    "X_Sp = X_Sp.drop('EL', axis = 1)\n",
    "X_Sp = X_Sp.drop('S8_cur', axis = 1)\n",
    "X_Sp = X_Sp.drop('V_cur', axis = 1)\n",
    "\n",
    "y_Sp = y['Sp_cur.1']\n",
    "\n",
    "X_numpy_Sp = X_Sp.values\n",
    "y_numpy_Sp = y_Sp.values\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train_Sp, X_test_Sp, y_train_Sp, y_test_Sp = train_test_split(X_numpy_Sp, y_numpy_Sp, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "3601/3601 [==============================] - 3s 743us/step - loss: 0.0466\n",
      "Epoch 2/20\n",
      "3601/3601 [==============================] - 3s 715us/step - loss: 1.3486e-04\n",
      "Epoch 3/20\n",
      "3601/3601 [==============================] - 3s 717us/step - loss: 1.0806e-04\n",
      "Epoch 4/20\n",
      "3601/3601 [==============================] - 3s 738us/step - loss: 8.2966e-05\n",
      "Epoch 5/20\n",
      "3601/3601 [==============================] - 3s 741us/step - loss: 4.1774e-05\n",
      "Epoch 6/20\n",
      "3601/3601 [==============================] - 3s 754us/step - loss: 3.4681e-05\n",
      "Epoch 7/20\n",
      "3601/3601 [==============================] - 3s 787us/step - loss: 3.5693e-05\n",
      "Epoch 8/20\n",
      "3601/3601 [==============================] - 3s 774us/step - loss: 2.7861e-05\n",
      "Epoch 9/20\n",
      "3601/3601 [==============================] - 3s 745us/step - loss: 2.8801e-05\n",
      "Epoch 10/20\n",
      "3601/3601 [==============================] - 3s 757us/step - loss: 2.2069e-05\n",
      "Epoch 11/20\n",
      "3601/3601 [==============================] - 3s 762us/step - loss: 2.9565e-05\n",
      "Epoch 12/20\n",
      "3601/3601 [==============================] - 3s 743us/step - loss: 1.7046e-05\n",
      "Epoch 13/20\n",
      "3601/3601 [==============================] - 3s 749us/step - loss: 1.6815e-05\n",
      "Epoch 14/20\n",
      "3601/3601 [==============================] - 3s 747us/step - loss: 1.8365e-05\n",
      "Epoch 15/20\n",
      "3601/3601 [==============================] - 3s 723us/step - loss: 1.6969e-05\n",
      "Epoch 16/20\n",
      "3601/3601 [==============================] - 3s 734us/step - loss: 1.9565e-05\n",
      "Epoch 17/20\n",
      "3601/3601 [==============================] - 3s 732us/step - loss: 1.7259e-05\n",
      "Epoch 18/20\n",
      "3601/3601 [==============================] - 3s 723us/step - loss: 1.2892e-05\n",
      "Epoch 19/20\n",
      "3601/3601 [==============================] - 3s 745us/step - loss: 1.4404e-05\n",
      "Epoch 20/20\n",
      "3601/3601 [==============================] - 3s 736us/step - loss: 1.2823e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1a35fcc86d0>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelp = Sequential()\n",
    "modelp.add(Dense(8, activation='relu', input_dim = 4))\n",
    "# model.add(Dense(6, activation='relu'))\n",
    "# model.add(Dense(12,activation = 'relu'))\n",
    "modelp.add(Dense(4,activation = 'relu'))\n",
    "# model.add(Dense(10, activation='relu'))\n",
    "modelp.add(Dense(1, activation='linear'))  # Output layer with a multiple neurons\n",
    "\n",
    "# Compile the model\n",
    "modelp.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "modelp.fit(X_train_Sp, y_train_Sp, epochs=20, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "901/901 [==============================] - 1s 622us/step - loss: 5.6115e-06\n",
      "Mean Squared Error on Test Set: 5.611478172795614e-06\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test set\n",
    "mse = modelp.evaluate(X_test_Sp, y_test_Sp)\n",
    "print(f\"Mean Squared Error on Test Set: {mse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Important functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bisection method function\n",
    "def f(V, EH, EL, scales):\n",
    "    # Defined in the code\n",
    "    iH0 = 10\n",
    "    iL0 = 5\n",
    "    R = 8.3145\n",
    "    T = 298\n",
    "    F = 96490\n",
    "    ar = 0.96\n",
    "    return 2 * iH0 * ar * np.sinh((2 * F / (R * T)) * (V - EH)) + 2 * iL0 * ar * np.sinh((2 * F / (R * T)) * (V - EL)) + scales.iloc[0,-1]\n",
    "\n",
    "# Bisection method adjusted to accept EH, EL, and I\n",
    "def bisection_method(V_a, V_b, EH, EL, scales, tol=1e-9, max_iter=10000):\n",
    "    if f(V_a, EH, EL, scales) * f(V_b, EH, EL, scales) >= 0:\n",
    "        print(\"Bisection method fails.\")\n",
    "        return None\n",
    "\n",
    "    V_m = V_a\n",
    "    for _ in range(max_iter):\n",
    "        V_m = (V_a + V_b) / 2\n",
    "        if f(V_m, EH, EL, scales) == 0 or np.abs(f(V_m, EH, EL, scales)) < tol:   # (V_b - V_a)/2\n",
    "            return V_m\n",
    "\n",
    "        if f(V_m, EH, EL, scales) * f(V_a, EH, EL, scales) < 0:\n",
    "            V_b = V_m\n",
    "        else:\n",
    "            V_a = V_m\n",
    "\n",
    "    return V_m  # Return the approximation of the root\n",
    "\n",
    "\n",
    "def param_finder_BV(V,EH,EL):\n",
    "    iH0 = 10\n",
    "    iL0 = 5\n",
    "    R = 8.3145\n",
    "    T = 298\n",
    "    F = 96490\n",
    "    ar = 0.96\n",
    "    iH = 2*iH0*ar*np.sinh((4*F*(V-EH))/(2*R*T))\n",
    "    iL = 2*iL0*ar*np.sinh((4*F*(V-EL))/(2*R*T))\n",
    "    return iH, iL\n",
    "\n",
    "\n",
    "\n",
    "def next_prediction(prediction, scales):\n",
    "\n",
    "    array = []\n",
    "\n",
    "    S8,S4,S2,S1,Sp,EH,EL = param_finder_Nernst(prediction,scale)\n",
    "\n",
    "    # Initial brackets (guesses) for V\n",
    "    V_a, V_b = 2.45,2.15 # Adjust these values based on your knowledge of the possible range of V\n",
    "\n",
    "    # Find V\n",
    "    V = bisection_method(V_a, V_b, EH, EL, scales)\n",
    "\n",
    "    # iH, iL = param_finder_BV(V,EH,EL)\n",
    "\n",
    "    V = (V - scales.iloc[0,4])/scales.iloc[1,4]\n",
    "\n",
    "    EH = (EH - scales.iloc[0,6])/scales.iloc[1,6]\n",
    "\n",
    "    EL = (EL - scales.iloc[0,7])/scales.iloc[1,7]\n",
    "\n",
    "\n",
    "    array.append(prediction[0][0])\n",
    "    array.append(prediction[0][1])\n",
    "    array.append(prediction[0][2])\n",
    "    array.append(prediction[0][3])\n",
    "    array.append(V)\n",
    "    array.append(prediction[0][4])\n",
    "    array.append(EH)\n",
    "    array.append(EL)\n",
    "\n",
    "    array = np.array([array])\n",
    "\n",
    "    return array \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def param_finder_Nernst(prediction, scales):\n",
    "    # Defined in the code\n",
    "    EH0 = 2.35\n",
    "    EL0 = 2.195\n",
    "    iH0 = 10\n",
    "    iL0 = 5\n",
    "    R = 8.3145\n",
    "    T = 298\n",
    "    F = 96490\n",
    "    fh = 0.7296\n",
    "    fl = 0.06654\n",
    "    ar = 0.96\n",
    "\n",
    "    # Unscale the concentration values to find S8 - Sp\n",
    "    S8 = (prediction[0][0] * scales.iloc[1,0]) + scales.iloc[0,0]\n",
    "    S4 = (prediction[0][1] * scales.iloc[1,1]) + scales.iloc[0,1]\n",
    "    S2 = (prediction[0][2] * scales.iloc[1,2]) + scales.iloc[0,2]\n",
    "    S1 = (prediction[0][3] * scales.iloc[1,3]) + scales.iloc[0,3]\n",
    "    Sp = (prediction[0][4] * scales.iloc[1,5]) + scales.iloc[0,5]\n",
    "\n",
    "    # S8 = (prediction[0][0])\n",
    "    # S4 = (prediction[0][1])\n",
    "    # S2 = (prediction[0][2])\n",
    "    # S1 = (prediction[0][3])\n",
    "    # Sp = (prediction[0][4])\n",
    "\n",
    "    # Unscaled EH, EL\n",
    "\n",
    "    EH = EH0 + (((R*T)/(4*F))*np.log(fh*(S8/(S4**2))))\n",
    "    EL = EL0 + (((R*T)/(4*F))*np.log(fl*(S4/((S1**2)*S2))))\n",
    "\n",
    "    return S8,S4,S2,S1,Sp,EH,EL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_numpy = X.values\n",
    "y_numpy = y.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def mass_prediction(input):\n",
    "    S8_features = ['S8_cur', 'S4_cur', 'V_cur', 'EH', 'EL']\n",
    "    S4_features = ['S4_cur','S2_cur', 'S1_cur', 'V_cur', 'Sp_cur','EH', 'EL']\n",
    "    S2_features = ['S4_cur','S2_cur', 'S1_cur', 'Sp_cur', 'EL']\n",
    "    S1_features = ['S4_cur','S2_cur', 'S1_cur', 'V_cur', 'Sp_cur','EH', 'EL']\n",
    "    Sp_features = ['S4_cur','S2_cur', 'S1_cur', 'Sp_cur']\n",
    "\n",
    "    # Reshape the input to ensure it's 2D\n",
    "    input_2d = input.reshape(1, -1)  # Reshape to 1 row, many columns\n",
    "\n",
    "    input_df = pd.DataFrame(input_2d, columns = ['S8_cur', 'S4_cur','S2_cur', 'S1_cur', 'V_cur', 'Sp_cur','EH', 'EL'])\n",
    "\n",
    "    S8_input = np.array(input_df[S8_features])\n",
    "    S4_input = np.array(input_df[S4_features])\n",
    "    S2_input = np.array(input_df[S2_features])\n",
    "    S1_input = np.array(input_df[S1_features])\n",
    "    Sp_input = np.array(input_df[Sp_features])\n",
    "\n",
    "    S8 = model8.predict(S8_input)[0][0]\n",
    "    S4 = model4.predict(S4_input)[0][0]\n",
    "    S2 = model2.predict(S2_input)[0][0]\n",
    "    S1 = model1.predict(S1_input)[0][0]\n",
    "    Sp = modelp.predict(Sp_input)[0][0]\n",
    "\n",
    "    array = [[S8,S4,S2,S1,Sp]]\n",
    "\n",
    "    return array\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.75583962 -2.76949624 -0.92914884 -0.23244107  2.28260561 -0.92512734\n",
      "   2.26101299  2.32763776]]\n",
      "1/1 [==============================] - 0s 22ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "no_predictions = 2\n",
    "start = 1500\n",
    "\n",
    "input = np.array([X_numpy[start]])\n",
    "\n",
    "print(input)\n",
    "\n",
    "output = []\n",
    "\n",
    "scale = pd.read_excel('C:/Users/ADITYA/OneDrive - Imperial College London/Year 4/FYP/Final-year-project/VScode/Data/Scales_denoised.xlsx')\n",
    "\n",
    "for i in range(no_predictions):\n",
    "    \n",
    "    next_prediction_array = mass_prediction(input)\n",
    "\n",
    "    input = next_prediction(next_prediction_array, scale)\n",
    "\n",
    "    # print(input)\n",
    "\n",
    "    output.append(input)\n",
    "\n",
    "\n",
    "\n",
    "plot_actual = []\n",
    "\n",
    "for j in range(no_predictions):\n",
    "    plot_actual.append(X_numpy[no_predictions + start][3])\n",
    "\n",
    "plt.plot(plot_actual, label = 'Actual')\n",
    "\n",
    "\n",
    "\n",
    "mass = []\n",
    "for i in range(len(output)):\n",
    "    mass.append(output[i][0][])\n",
    "\n",
    "plt.plot(mass, label = 'Predicted')\n",
    "plt.xlabel('Time step')\n",
    "plt.ylabel('Voltage')\n",
    "plt.title('Predicted vs Actual forecasting only masses')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
