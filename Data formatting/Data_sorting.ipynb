{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data sorting algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADITYA\\AppData\\Local\\Temp\\ipykernel_14440\\1442840785.py:2: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Interpolator function:\n",
    "\n",
    "The dataset consists of uneven time increments and thus the important columns such as S8,S4,S2,S1,V,Sp require interpolated values for a constant time increment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolator(dataset, time_increment):\n",
    "    # Ensure dataset is a NumPy array and storing current and cycle columns\n",
    "    dataset = np.array(dataset)\n",
    "    current_value = dataset[0, 7]\n",
    "    cycle_number_value = dataset[0, 8]\n",
    "\n",
    "    # Calculate the minimum and maximum time values in the array\n",
    "    min_time = dataset[:, 6].min()  \n",
    "    max_time = dataset[:, 6].max()\n",
    "\n",
    "    # Create a new array with the desired time increments\n",
    "    new_time_values = np.arange(min_time, max_time, time_increment)\n",
    "\n",
    "    # Forming an array for interpolated values\n",
    "    interpolated_values = np.zeros((len(new_time_values), 6))\n",
    "\n",
    "    # Interpolate columns\n",
    "    for col_index in range(6):  # Adjust the range if the number of columns to interpolate differs\n",
    "        interpolated_values[:, col_index] = np.interp(new_time_values, dataset[:, 6], dataset[:, col_index])\n",
    "\n",
    "    # Combine interpolated values with constant values and new time values\n",
    "    interpolated_data = np.column_stack((interpolated_values, new_time_values, np.full(len(new_time_values), current_value),\n",
    "                                         np.full(len(new_time_values), cycle_number_value)))\n",
    "\n",
    "    # Convert the result to a pandas DataFrame\n",
    "    column_names = ['S8_cur', 'S4_cur','S2_cur','S1_cur','V_cur', 'Sp_cur', 't_cur','I', 'cycle number']  # Adjust column names as needed\n",
    "    interpolated_df = pd.DataFrame(interpolated_data, columns=column_names)\n",
    "\n",
    "    return interpolated_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Functions for Nernst potentials and BV partial currents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defined in the code\n",
    "EH0 = 2.35\n",
    "EL0 = 2.195\n",
    "iH0 = 10\n",
    "iL0 = 5\n",
    "R = 8.3145\n",
    "T = 298\n",
    "F = 96490\n",
    "fh = 0.7296\n",
    "fl = 0.06654\n",
    "ar = 0.96\n",
    "\n",
    "def high_Nernst(EH0,R,T,F,fh,S8,S4):\n",
    "  EH = EH0 + (((R*T)/(4*F))*np.log(fh*(S8/(S4**2))))\n",
    "  return EH\n",
    "\n",
    "def low_Nernst(EL0,R,T,F,fl,S4,S2,S):\n",
    "  EL = EL0 + (((R*T)/(4*F))*np.log(fl*(S4/((S**2)*S2))))\n",
    "  return EL\n",
    "\n",
    "def high_BV(iH0,ar,F,R,T,V,EH):\n",
    "  iH = 2*iH0*ar*np.sinh((4*F*(V-EH))/(2*R*T))\n",
    "  return iH\n",
    "\n",
    "def low_BV(iL0,ar,F,R,T,V,EL):\n",
    "  iL = 2*iL0*ar*np.sinh((4*F*(V-EL))/(2*R*T))\n",
    "  return iL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Scaler function for X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaler_func(X,y,current):\n",
    "    \n",
    "    # Scaling dataset for all the cycles combined (specific current)\n",
    "    scale_columns_cur_X = ['S8_cur', 'S4_cur', 'S2_cur', 'S1_cur', 'V_cur', 'Sp_cur','EH','EL','iH','iL']\n",
    "    scale_columns_cur_y = ['S8_cur', 'S4_cur', 'S2_cur', 'S1_cur', 'Sp_cur', 'V_cur']\n",
    "\n",
    "    means = X[scale_columns_cur_X].mean()\n",
    "    stds = X[scale_columns_cur_X].std()\n",
    "\n",
    "    # Create a new DataFrame to store these values\n",
    "    scales = pd.DataFrame([means, stds], index=['mean', 'std'])\n",
    "\n",
    "    for i in scale_columns_cur_X:\n",
    "        X[i] = (X[i] - scales.loc['mean', i]) / scales.loc['std', i]\n",
    "\n",
    "\n",
    "    for j in scale_columns_cur_y:\n",
    "        y[j] = (y[j] - scales.loc['mean', j])/scales.loc['std', j]\n",
    "\n",
    "    scales['I'] = current\n",
    "\n",
    "    return scales,X,y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5) Data formatter for each current and multiple cycles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Data_formatter_cycles(current, data):\n",
    "\n",
    "    X_cycles = pd.DataFrame(columns=['S8_cur', 'S4_cur', 'S2_cur', 'S1_cur', 'V_cur', 'Sp_cur', 'I', 'EH', 'EL', 'iH', 'iL'])\n",
    "    y_cycles = pd.DataFrame(columns=['S8_cur', 'S4_cur', 'S2_cur', 'S1_cur', 'Sp_cur' , 'V_cur'])\n",
    "\n",
    "    # Extract unique cycle numbers to know how many times data formatting is required for particular cycle number\n",
    "    unique_cycles = data['cycle'].unique()\n",
    "    cycles = len(unique_cycles)\n",
    "\n",
    "    # Defining scaling parameters\n",
    "    scales = pd.DataFrame(columns=['S8_cur', 'S4_cur', 'S2_cur', 'S1_cur', 'V_cur', 'Sp_cur', 'I', 'EH', 'EL', 'iH', 'iL'])\n",
    "\n",
    "    # Defining parameter\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    for i in range(cycles):\n",
    "\n",
    "        # Define the input dataset for the particular cycle\n",
    "        X_array = data[data['I'] == current]\n",
    "        X_array = X_array[X_array['cycle'] == i]\n",
    "        X_array = X_array.iloc[1:,1:] # Removing first row as it has erraneous values\n",
    "\n",
    "\n",
    "        # Linearly interpolating timescale for even data\n",
    "        time_increment = 0.05\n",
    "        X_array_interpolated = interpolator(X_array, time_increment)\n",
    "\n",
    "        # Apply the functions to the desired columns\n",
    "        X_array_interpolated['EH'] = X_array_interpolated.apply(lambda row: high_Nernst(EH0, R, T, F, fh, row[0], row[1]), axis=1)\n",
    "        X_array_interpolated['EL'] = X_array_interpolated.apply(lambda row: low_Nernst(EL0, R, T, F, fl, row[1], row[2], row[3]), axis=1)\n",
    "        X_array_interpolated['iH'] = X_array_interpolated.apply(lambda row: high_BV(iH0, ar, F, R, T, row[4], row['EH']), axis=1)\n",
    "        X_array_interpolated['iL'] = X_array_interpolated.apply(lambda row: low_BV(iL0, ar, F, R, T, row[4], row['EL']), axis=1)\n",
    "\n",
    "        # Defining input array for NN\n",
    "        filter_columns_cur = ['S8_cur', 'S4_cur', 'S2_cur', 'S1_cur', 'V_cur', 'Sp_cur','I','EH','EL','iH','iL']\n",
    "        X_array_interpolated = X_array_interpolated[filter_columns_cur]\n",
    "\n",
    "        # Defining output array\n",
    "        filter_columns_nxt = ['S8_cur', 'S4_cur', 'S2_cur', 'S1_cur','Sp_cur', 'V_cur']\n",
    "        y_interpolated = X_array_interpolated[filter_columns_nxt]\n",
    "\n",
    "        # Setting current input and next output\n",
    "        y_interpolated = y_interpolated.iloc[1:,:]\n",
    "        X_array_interpolated = X_array_interpolated.iloc[:-1,:]\n",
    "        \n",
    "        # Removing first value as it is erraneous\n",
    "        y_interpolated = y_interpolated.iloc[1:,:]\n",
    "        X_array_interpolated = X_array_interpolated.iloc[1:,:]\n",
    "\n",
    "        # Append interpolated data to X\n",
    "        X_cycles = pd.concat([X_cycles, X_array_interpolated[X_cycles.columns]], ignore_index=True)\n",
    "\n",
    "        # Append subset of interpolated data to y\n",
    "        y_cycles = pd.concat([y_cycles, y_interpolated[y_cycles.columns]], ignore_index=True)\n",
    "\n",
    "\n",
    "    # scales,X,y = scaler_func(X_cycles,y_cycles,current)\n",
    "\n",
    "    return X_cycles, y_cycles\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6) Saving data into an excel file to check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADITYA\\AppData\\Local\\Temp\\ipykernel_14440\\2149632572.py:29: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  X_array_interpolated['EH'] = X_array_interpolated.apply(lambda row: high_Nernst(EH0, R, T, F, fh, row[0], row[1]), axis=1)\n",
      "C:\\Users\\ADITYA\\AppData\\Local\\Temp\\ipykernel_14440\\2149632572.py:30: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  X_array_interpolated['EL'] = X_array_interpolated.apply(lambda row: low_Nernst(EL0, R, T, F, fl, row[1], row[2], row[3]), axis=1)\n",
      "C:\\Users\\ADITYA\\AppData\\Local\\Temp\\ipykernel_14440\\2149632572.py:31: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  X_array_interpolated['iH'] = X_array_interpolated.apply(lambda row: high_BV(iH0, ar, F, R, T, row[4], row['EH']), axis=1)\n",
      "C:\\Users\\ADITYA\\AppData\\Local\\Temp\\ipykernel_14440\\2149632572.py:32: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  X_array_interpolated['iL'] = X_array_interpolated.apply(lambda row: low_BV(iL0, ar, F, R, T, row[4], row['EL']), axis=1)\n",
      "C:\\Users\\ADITYA\\AppData\\Local\\Temp\\ipykernel_14440\\2149632572.py:51: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  X_cycles = pd.concat([X_cycles, X_array_interpolated[X_cycles.columns]], ignore_index=True)\n",
      "C:\\Users\\ADITYA\\AppData\\Local\\Temp\\ipykernel_14440\\2149632572.py:54: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  y_cycles = pd.concat([y_cycles, y_interpolated[y_cycles.columns]], ignore_index=True)\n",
      "C:\\Users\\ADITYA\\AppData\\Local\\Temp\\ipykernel_14440\\2149632572.py:29: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  X_array_interpolated['EH'] = X_array_interpolated.apply(lambda row: high_Nernst(EH0, R, T, F, fh, row[0], row[1]), axis=1)\n",
      "C:\\Users\\ADITYA\\AppData\\Local\\Temp\\ipykernel_14440\\2149632572.py:30: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  X_array_interpolated['EL'] = X_array_interpolated.apply(lambda row: low_Nernst(EL0, R, T, F, fl, row[1], row[2], row[3]), axis=1)\n",
      "C:\\Users\\ADITYA\\AppData\\Local\\Temp\\ipykernel_14440\\2149632572.py:31: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  X_array_interpolated['iH'] = X_array_interpolated.apply(lambda row: high_BV(iH0, ar, F, R, T, row[4], row['EH']), axis=1)\n",
      "C:\\Users\\ADITYA\\AppData\\Local\\Temp\\ipykernel_14440\\2149632572.py:32: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  X_array_interpolated['iL'] = X_array_interpolated.apply(lambda row: low_BV(iL0, ar, F, R, T, row[4], row['EL']), axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          S8_cur    S4_cur    S2_cur        S1_cur    Sp_cur     V_cur\n",
      "0       2.688960  0.002940  0.002697  3.522778e-09  0.000003  2.428108\n",
      "1       2.688880  0.003020  0.002697  3.668722e-09  0.000003  2.427763\n",
      "2       2.688800  0.003100  0.002697  3.815523e-09  0.000003  2.427427\n",
      "3       2.688720  0.003180  0.002697  3.964209e-09  0.000003  2.427100\n",
      "4       2.688640  0.003260  0.002697  4.114778e-09  0.000003  2.426781\n",
      "...          ...       ...       ...           ...       ...       ...\n",
      "144008  0.000246  1.406538  0.645255  1.941675e-04  0.642366  2.290260\n",
      "144009  0.000246  1.406511  0.645268  1.941655e-04  0.642380  2.290259\n",
      "144010  0.000246  1.406485  0.645282  1.941636e-04  0.642393  2.290259\n",
      "144011  0.000246  1.406458  0.645295  1.941616e-04  0.642406  2.290259\n",
      "144012  0.000246  1.406432  0.645308  1.941597e-04  0.642419  2.290259\n",
      "\n",
      "[144013 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_excel('C:/Users/ADITYA/OneDrive - Imperial College London/Year 4/FYP/Final-year-project/VScode//Data/Dataset.xlsx')\n",
    "current = 1.6\n",
    "\n",
    "X_cycles, y_cycles = Data_formatter_cycles(current, data)\n",
    "\n",
    "print(y_cycles)\n",
    "\n",
    "# Join the DataFrames side by side\n",
    "combined_df_unscaled = pd.concat([X_cycles, y_cycles], axis=1)\n",
    "\n",
    "# Save the combined DataFrame as an Excel file for unscaled data\n",
    "combined_df_unscaled.to_excel('C:/Users/ADITYA/OneDrive - Imperial College London/Year 4/FYP/Final-year-project/VScode//Data/Dataset_unscaled.xlsx', index=False)\n",
    "\n",
    "\n",
    "scales,X,y = scaler_func(X_cycles,y_cycles,current)\n",
    "\n",
    "\n",
    "# Join the DataFrames side by side\n",
    "combined_df_scaled = pd.concat([X, y], axis=1)\n",
    "\n",
    "# Save the combined DataFrame as an Excel file\n",
    "combined_df_scaled.to_excel('C:/Users/ADITYA/OneDrive - Imperial College London/Year 4/FYP/Final-year-project/VScode//Data/Dataset_scaled.xlsx', index=False)\n",
    "\n",
    "scales.to_excel('C:/Users/ADITYA/OneDrive - Imperial College London/Year 4/FYP/Final-year-project/VScode/Data/Scales.xlsx', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
